




本科毕业论文（设计）



 论文题目（中文） 基于深度学习的冷冻电镜图片降噪研究                                 
 论文题目（英文）                                        
                                                                


              学生姓名                
 
             指导教师                

             学    院                

             专    业                

             年    级                


兰州大学教务处

诚信责任书
本人郑重声明：本人所呈交的毕业论文（设计），是在导师的指导下独立进行研究所取得的成果。毕业论文（设计）中凡引用他人已经发表或未发表的成果、数据、观点等，均已明确注明出处。除文中已经注明引用的内容外，不包含任何其他个人、集体已经发表或未发表的论文。
本声明的法律责任由本人承担。


论文作者签名：                                日  期：              

关于毕业论文（设计）使用授权的声明
本人在导师指导下所完成的论文及相关的职务作品，知识产权归属兰州大学。本人完全了解兰州大学有关保存、使用毕业论文（设计）的规定，同意学校保存或向国家有关部门或机构送交论文的纸质版和电子版，允许论文被查阅和借阅；本人授权兰州大学可以将本毕业论文（设计）的全部或部分内容编入有关数据库进行检索，可以采用任何复制手段保存和汇编本毕业论文（设计）。本人离校后发表、使用毕业论文（设计）或与该毕业论文（设计）直接相关的学术论文或成果时，第一署名单位仍然为兰州大学。
本毕业论文（设计）研究内容：
□可以公开
□不宜公开，已在学位办公室办理保密申请，解密后适用本授权书。
（请在以上选项内选择其中一项打“√”）


论文作者签名：                           导师签名：                
日        期：                           日    期：                



基于深度学习的冷冻电镜图片降噪研究
中文摘要
摘要：冷冻电镜是结构生物学中的重要实验工具；而冷冻电镜图像的降噪处理是一个重要的研究课题。近年来深度学习技术被广泛用于图片降噪领域，本文将探究深度学习在冷冻电镜图像降噪中的作用。
关键词：冷冻电镜 图像降噪 深度学习

 
Studies in Analytic Philosophy in China
Abstract 
This thesis explores the history of studies in analytical philosophy in China, which is divided into three phases since the beginning of the 20th century. It demonstrates that space analytic philosophy space has always been at a disadvantage in the three phases, confronting serious challenges from both Chinese traditional philosophy and modern philosophical trends. The authors argue that Chinese philosophers have not just done preliminary studies but also offered their own analyses of various problems, especially  the new applications of analytic philosophy in the latest period. Meanwhile, in its struggle with analytic philosophy, Chinese traditional philosophy has always been trying to adjust its cultural mentality and accommodated, in its own way, the rationalistic spirit and scientific method represented in analytic philosophy.

Keywords: analytical philosophy; Chinese philosophers; philosophical analysis;dialogue in philosophy.

[该英文摘要引自Synthese (2010) 175: 3-12.，个别内容有修改]

 

目录
Abstract	IV
引 言	1
第一章  研究意义与文献调研	2
1.1	研究意义	2
1.2	文献调研	3
1.3	文章结构	3
第二章  原理阐述	3
2.1	噪声	3
2.2	机器学习与深度学习的原理	4
2.3	CNN	4
2.4	Noise2Noise	5
2.5	Noise2Void	6
2.6	去噪效果的评价指标	6
致  谢	7



图/表  目  录
1.1  总体数据分析..........................................5
1.2  总体数据分析..........................................8

 
引 言
××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××
××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××













 
第一章  研究意义与文献调研
1.1	研究意义
生物大分子三维结构与功能之间的关系是现代生命科学、材料学和应用物理的一个重要研究领域。 
    在病毒研究领域，了解病毒的分子结构有助于从分子层面理解其组装和行使功能的机制；在医学和药物研发领域，对生物分子结构的研究已广泛应用于基于结构的新药开发；在人体内代谢的研究中，其有助于理解人体蛋白质结构与其相互作用机制。
    冷冻电镜技术结合了冷冻电子显微技术三维重构技术，能将含水生物大分子迅速冷冻至液氮或液氦温度，避免生物大分子结构在产生晶态冰的过程中被破坏；非晶冰还使得保证冷冻电镜环境下生物分子中的水得以保存，使其接近于生理活性状态。以上特点使得冷冻电镜可以在原子分辨率水准下研究生物大分子的结构。为了防止样品在观察过程中受到高能电子束的辐射损伤，一般只能采用低剂量的电子照射，这使得在冷冻电镜图像的信噪比很低，因此，图像降噪是冷冻电镜解析生物大分子的重要环节。
    传统的图像去噪方法一般采用均值滤波、高斯滤波、维纳滤波等滤波技术。这些方法在冷冻电镜图片降噪中被广泛使用；高斯滤波器被用于在单颗粒分析过程中对颗粒进行识别；维纳滤波器被用于生物大分子结构的三维重建；迭代中值滤波器被用于对冷冻电子断层结构重建图进行特征提取、模式识别。虽然滤波器降噪的应用广泛，但是每种滤波器都存在其局限性：高斯滤波后的图像会变得更加模糊；中值滤波器受到滑动模板尺寸的限制：模板过大会破坏图像细节；模板过小则不能有效去除噪声。总体而言，现有的滤波器种类繁多，但是每种滤波器都有一定的缺点和局限。
    近年来，除开传统的滤波器去噪，深度学习技术也逐渐被应用于图片降噪处理。深度学习是机器学习的分支，是一种以人工神经网络为架构，对大量数据进行表征学习的算法。通过设计网络结构，使用大量数据进行参数训练，深度神经网络模型能够以较高的准确率完成图像增强，图像降噪，特征提取等图像处理工作。相比传统图片降噪技术，深度学习更加适合冷冻电镜这类大规模数据集，其神经网络参数可变，随着训练数据量增大而自动优化，减少了需要人力操作的步骤；同时，深度学习还可引入自动图像分割等功能，更好地完成颗粒挑选等工作；根据冷冻电镜图像的特征设计神经网络层次结构，可以更加充分地利用图像信息，保留图片细节。目前，深度学习降噪更多地被用于通用图片处理，针对冷冻电镜图像设计的深度神经网络主要还停留于基础的卷积神经网络（CNN）。通过结合冷冻电镜的图像特征，借鉴现有的神经网络结构，参考传统滤波降噪方法，我们可以设计出更加适合冷冻电镜图像降噪处理的深度学习模型。

    本课题尝试基于深度学习方法，对比现有图片降噪技术，提出针对冷冻电镜图片降噪新思路，助力生物大分子高分辨三维结构的解析，从而为揭示生物大分子三维结构与功能的关系奠定基础。
1.2	文献调研
    文献调研如下
1.3	文章结构
本文分为4章。其中第一章阐述研究意义，第二章介绍本文涉及的概念和前置理论知识，第三章实现前人提出的去噪模型，并比较其降噪效果，第四章对前人的去噪模型进行修改，并比较降噪效果。
第二章  原理阐述
2.1	噪声
由于环境、传输通道等因素的影响，图像在采集、压缩和传输过程中不可避免地受到噪声的污染，导致图像信息失真和信息丢失。
图像去噪是从有噪声的图像中去除噪声，从而恢复真实的图像。然而，由于噪声、边缘和纹理是高频分量，在去噪过程中很难区分它们，去噪后的图像不可避免地会丢失一些细节。总体而言，在去噪过程中从噪声图像中恢复有意义的信息以获得高质量的图像是当今的一个重要问题。
事实上，图像去噪是一个经典的问题，尽管针对图像去噪已经有相当多的研究工作，它仍然是一项具有挑战性和开放性的任务。从数学的角度来看，主要原因是图像去噪是一个逆问题，其解并不唯一。

在数学上，图像去噪问题可以建模如下：
y = x + n
其中y是观察到的噪声图像，x是未知的干净图像，n表示噪声分量，降噪的目的是降低自然图像中的噪声，同时尽量减少原始特征的损失，提高信噪比（SNR）。由于从等式求解干净的图像 x是一个不适定问题，我们无法从有噪声的图像模型中得到唯一解。图像去噪的主要挑战如下：

1.物体平坦的区域的复原效果应该是光滑的
2.边缘应受到保护而不会模糊
3.在保留图像原本纹理的同时不会生成新的纹理

一般来说，图像去噪方法可以大致分为空间域方法和变换域方法，在接下来的章节中将更详细地介绍。
2.2	机器学习与深度学习的原理

机器学习是人工智能的一个分支，通过对大量数据进行学习，从而模仿人类完成分类、预测等任务。
所有机器学习的任务都需要如下要素：
1.可以供我们进行训练的数据
2.对数据进行运算的模型
3.一个目标函数，用于对模型的真实性和适用性进行量化检验
4.通过调整模型参数而实现模型优化的算法
在机器学习中，训练过程包括如下步骤：
1.从随机初始化参数的模型开始，该模型基本上不具备智能
2.获取数据样本（图像、标签等）
3.调整参数，使得对于训练集，模型能给出的预测效果可以与样本相符
4.重复第二步和第三步，知道模型能以较好的效果完成指定任务
传统的机器学习算法一般可根据是否需要数据标签而分为有监督学习和无监督学习。一个典型的有监督式学习任务在观察完一些事先标记过的训练示例（输入和预期输出）后，训练出来的模型可以对新的输入进行预测。而无监督学习算法不需要给定事先标记过的训练样本，可以自动对输入的数据进行分类或预测。

深度学习是机器学习的分支，通过构建深层次的人工神经网络，能更好的提取出数据中的特征。深度学习应用于图像处理时，输入数据一般是一个多维数组，而深度学习技术的主要任务就是从中抽取出一系列特征，例如图像实体的边界、特定形状的区域等。比起比起传统的机器学习，深度学习算法更多地倾向于无监督或半监督式的特征学习，能利用高效的特征提取算法来代替手工获取图像特征，从而更好地从大规模未标记的数据中学习其特征。

目前学界已经提出多种深度学习框架，如深度神经网络，卷积神经网络和循环神经网络等。这些网络模型已被大量地运用到图像处理、计算机视觉等领域并取得巨大成功。
2.3	CNN
卷积神经网络主要由卷积层、池化层、全连接层三种网络层组成。

卷积层的思想来源于对人和动物视觉系统的研究。动物视觉系统在处理图像时，是分层抽象的，其最先关注的是颜色和亮度，然后是直线、边缘、点等局部的细节特征，再之后是纹理、集合形状等更加复杂的结构和信息，而后形成对物体的整体感知。

卷积层模仿的正式这个特征抽取的过程：在输入图像上滑动不同的卷积核并执行一定的运算，从而产生特征图(feature map)。在滑动过程中，卷积核与图像之间会执行卷积运算，将当前感受域中的元素乘以对应的卷积核系数，最终求和，从而将感受域内的信息投影到特征图上的一个元素。卷积核的尺寸比输入图像小得多，或重叠或平行地作用于输入图像上。进行一轮卷积核滑动下来可以得到一张特征图，将此过程不断重复即可得到多张平行地特征图，每一张都从上一张得到更抽象的信息，从而提取物体从微观到宏观的特征。

池化是卷积神经网络中另一个重要网络层。池化层的主要作用是不断缩小数据的空间大小，从而使得参数数量和计算量都大大下降，并且在一定程度上可以控制过拟合的现象。以常用的最大池化为例，它的主要操作是将输入的图像分割为若干大小的区域，每个子区域输出其最大值。和卷积层类似，步幅也是池化层的重要参数。当池化步幅为2时，池化窗口的形状为2*2，从窗口中的4个数中取出最大值，能够减少75%的数据量，减轻运算负担。这种机制能够有效工作的主要原因是，在一副图像中，特征区域往往只集中于其中的一小块；数值较大的像素点对图像的影响远超过数值较小的像素点。同时，池化层在某种程度上为图像处理提供了另一种形式的平移不变形：卷积核是一种特征发现器，可以用它较容易的发现图像的边缘细节。大但是卷积层发现的特征通常过于精确，通过池化操作我们可以降低其对边缘的敏感性，从而改善过拟合的现象。

全连接层负责将卷积层和池化层的处理映射到最终的输出上。全连接层的神经元与其前一层的所有神经元都有连接，用于把之前提取的特征综合起来输出为一个值。
2.4	Noise2Noise

以CNN为代表的去噪算法可以归结为如下问题的解决：

![image-20220406175935532](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220406175935532.png)

上面式子中，f是网络模型对应的函数，x是输入的带噪声图像；y是理想的无噪图像，L是衡量降噪结果与真实图像之间差异的损失函数。上式的数学意义是，对于所有的图像对(x,y)，通过调整网络参数theta，使得Loss函数的均值最小。

在以CNN为核心的去噪算法中，人们一般需要知道完全洁净无噪声的原始数据和加了噪声的加噪数据；两者之差即为需要学习的噪声特征。这样的过程可以被归为有监督学习；然而在处理冷冻电镜图像时，人们往往难以获得完全无噪声的原始数据，由此需要发展出完全利用噪声数据来进行学习的无监督网络训练方法。

Noise2Noise正是一种无需洁净数据集的网络训练方案。其主要思想接近于通过多次求平均值来减小测量误差的处理方法。Noise2Noise方法的数学表述如下：

![image-20220406195249614](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220406195249614.png)

xi和yi代表对同一个实体的两次摄像，每次摄像都存在噪音，但是对于x和y来说其噪音是独立同分布的。当我们对多个实体进行摄像，即可得到多个(x,y)对，这些图像对构成了优化网络参数所需的训练集。如果Loss函数选取合适，则经过多轮训练后得出的网络模型f满足如下特性：若我们构造出另一组图片集z，使得z的噪声均值跟y的噪声均值相等，那么用(x,y)点对训练出来的网络模型将完全等价于用(x,z)点对的网络模型；换言之，如果我们使用带有噪声但是噪声均值为0的数据集进行训练，得出来的模型跟噪声-洁净集的训练结果完全等价。

2.5	Noise2Void
Noise2Void方法是对Noise2Noise方法的进一步拓展。Noise2Noise摆脱了对于理想数据集的依赖，Noise2Void则摆脱了对数据对的依赖，仅凭一张图片来训练网络实现去噪。

在一般的CNN训练过程中，网络输出的每一个像素都对应一个感受野，也就是感受野范围内所有像素都对输出值有影响。而在Noise2Noise的训练中采用的是盲点网络：这种网络会忽略感受野的中心值，其中心就是一个盲点。由此，网络的输出值受到其周围所有像素的影响（除了自身位置的输入）。

该网络的基本假设是：同一张图片的不同像素上的噪声是不相关的。在训练过程中，盲点网络将试图用一个像素周围的其它像素来复原该像素，但是由于像素间的噪声互不相关，最终被复原出来的只有真实图像信息。而采用盲点网络而非全CNN网络，是因为如果将中心位置的像素也加入到训练中，会使得网络学习到恒等映射，将输入图片原样返回，从而达不到降噪的目的。

与Noise2Noise网络相比，其需要的数据更少，但是由于它使用的是与Noise2Noise类似的机制，所以其训练效果并不会比Noise2Noise网络更佳，反而会因为在训练中没有使用所有可用的图像信息，其准确率也会有所下降。
2.6	

2.7	去噪效果的评价指标
图片降噪的效果有主观评价和客观评价两种评价方法。其中主观评价是指人工根据主观感受来对降噪效果进行评定，不同观察者往往得出不同的评价结论，使用主观评价对图像降噪效果进行评测并不严谨，本文将更加注重客观评价指标。
客观评价指标又分为：全参考评价、部分参考评价、无参考评价三类。

全参考评价需要完整的参考图片，通过对参考图片和降噪图片的每一个像素进行对比，计算其差异值。差异值越大，说明降噪效果越差；反之降噪效果则越好。图像去噪领域的论文中常用峰值信噪比来进行评价，这也是目前最广泛被使用的评价指标。

部分参考指标是指获取两幅图像的部分信息来进行对比，常用的方法是结构相似性比较。

无参考评价不需要参考图像。通过学习大量数据样本，提取相应特征得出评价值；生成对抗网路中的判别模型就是此类指标。

本文将使用两种数值评价指标：傅里叶环相关性， 图片互相关系数。

第三章 网络结构与训练方案
一个深度学习任务由以下因素决定：网络模型的结构、训练网络模型所用的数据、训练时采用的损失函数、训练中使用的参数优化策略
网络结构层次。
3.1	网络结构

本文设计的网络架构主要包括四种类型的网络层：卷积层，池化层，非线性激活层，全连接层。网络整体由多个块组成，每个块包含以上四种类型的网络层的一层或多层。由于在卷积过程中，图片尺寸会缩小，因此图片在网络中会经过编码和解码过程。

编码器由4层组成，分别为enc1, enc2, enc3, enc4。
每一层enc可表述为：

enc = Sequential(Conv2d, Relu, MaxPool2d)
其中Conv2d表示卷积层，Relu表示Relu激活函数层，MaxPool2d表示最大池化层。三层呈序列排布。

每个enc的Relu层和MaxPool2d层都相同，不同的是每个enc的卷积层采取了不同的窗口大小。由于最佳窗口大小取决于图像细节的尺寸，无法在一开始便确定下来。所以窗口大小是多次尝试后，根据降噪效果和收敛速率等指标选取的。

解码器负责将图片像素增加。一张图片经过多个卷积层以后，像素数量会大大减小，每个像素承载的信息量也大大增加，保留了图像的主要特征。为了从主要特征中恢复出跟原图等量的像素，人们一般采用插值的方法。因此每个解码器都等价于一个插值函数。

带有噪声的图像经过编码器和解码器运算后，就得到相同尺寸的降噪图像。

以上是网络层次的具体构成，接下来阐述构造这个网络的思路，也就是为什么要设计这样的网络结构。


复杂的网络结构是由简单的“块”组成的。在神经网络模型中，进行一次向量化运算并得到对应输出的结构叫做层，多个层叠加起来组成块，块的重复叠合则组成了整个模型结构。在计算机视觉领域广泛使用的ResNet结构就有数百个层次，但是层次的种类并不多，这些曾是由相同的层组块重复叠加而成。ResNet架构在多种计算机视觉任务中都是首选架构，在其他的领域，如自然语言处理和语音处理，层组块重复排列的模式也普遍存在。事实证明，讨论比单个层大但比整个模型小的组件更有价值。将模型设计为多个相似的enc和dec采用的就是这种思想。

从编程的角度看，每个块的程序实现都是一个类(class)，每个表示神经网络层的类都必须定义一个将其输入转化为输出的前向传播函数，并且存储所需的参数。而为了计算梯度，每个块也必须定义反向传播函数。在编程实现中，深度学习的框架都为我们提供了自动微分的默认实现，因此在编写程序时我们只定义了前向传播函数和参数。

卷积层和池化层的作用之前已经提到，事实上，几乎每个图像处理的深度学习方法都使用了这两个层次来进行特征提取。而引入Relu函数层的主要目的是提高模型的非线性特性。以下将具体解释这个网络层的作用。
当我们构建深度网络模型是，我们都希望该模型具有足够的表达力，能够真实地反映输入和出之间的关系。神经网络模满足如下表达式：
f(x)=y
f是神经网络对应的函数，x和y对应输入和输出。一般来说，真实世界的f总是对应非线性的函数，这要求我们的网络模型也具有一定的非线性。最早期的网络模型是多层感知机模型，该模型的包含输入层、输出层和隐藏层。其中的每一层都对应线性函数；增加隐藏层的数目会增加参数量和计算量，然而事实证明，这并不会给模型带来改善：多层线性网络层可以被完全规约为具有更多参数的单层线性层，通过多个线性层叠加出来的模型仍然只具有线性表达力。
为了是模型具有线性特性，我们必须改造其中的层次，将隐藏层中的一层或多层替换为非线性函数。这种函数被称为激活函数。
非线性函数多种多样，目前主流深度学习使用的激活函数是Sigmoid函数、Tanh函数、Relu函数。
、
1.sigmoid函数
sigmoid函数又名logitstic函数，它的取值范围为(0,1)，数学表达式：

图像是：

其优点是：其输出范围有限，可以作为输出层使用。
其主要的缺点是饱和问题：当输入值的绝对值非常大时，函数会趋向于常数，形状变得非常平缓，因此对于输入的变化变得不敏感。

2. Tanh函数
数学表达式：
图像：
3. Relu函数
Relu函数整流线性函数，它是现代神经网络中应用最广泛的激活函数。
数学表达式：
图像：
其优点是使用Relu函数的模型，训练收敛速率更快。
在x>0的区域上不会出现前两者的梯度饱和问题。

鉴于Relu函数是深度学习最常用的激活函数，且具有以上诸多优点，因此我们的网络模型也采用它作为激活函数。

以上介绍了我们网络模型中出现的神经层种类。接下来解释解码器的构成。
图像经过卷积层的处理可以看做是经历了一次下采样，也即从大量数据中采样出少部分数据；而解码器则是一个上采样的过程。双线性插值是一种常用的上采样方法。
双线性插值的含义如下：
双线性插值直接找到原图像的对应点，将数值赋予新矩阵对应点；新矩阵的点比原矩阵更密集，当遇到没有没有原矩阵对应的点时，采取其最邻近的点作线性插值，算出新值赋予新矩阵。
3.2	损失函数

损失函数是衡量模型预测结果与真实值之间差距的数值指标。深度学习的训练过程可以看做通过调整网络参数，使得网络的输出预测值与真实值之间的Loss最小。Loss函数的选择直接影响了模型的预测准确率、泛化能力、收敛速度等重要指标。
常用的Loss函数有：

平均绝对误差函数(L1 Loss)
平均绝对误差衡量的是模型预测值与真实值差值的绝对值的均值。计算公式如下：
![](2022-04-08-18-09-55.png)
函数的图像如图：
![](2022-04-08-18-10-33.png)
L1 Loss曲线是连续的，除0以外都可导，且导数为常数。这种特性使得在训练过程中对于各种输入值都能得到稳定的梯度，避免了梯度爆炸的现象，解的鲁棒性较强。但是同时，常数梯度值会导致对于较大的损失值也采用了同样的梯度，影响了训练的收敛速率。

均方误差 （L2 Loss）
均方误差衡量的是模型预测值与真实样本差值平方的均值，其计算公式如下：
![](2022-04-08-18-17-44.png)
其图像如下:
![](2022-04-08-18-18-05.png)
MSE的函数光滑连续且每一处均可导。MSE能较好地反映出误差和梯度的关系：误差较大时，梯度也较大，这提高了训练过程的收敛速度。
除了影响模型的收敛速率外，收敛函数的选择也也会影响到网络模型的效果。
L1 Loss和L2 loss学习到的信息并不完全相同。当Loss函数达到最小是，L1 loss倾向于学习到数据集的中值；而L2 loss倾向于学习到数据集的平均值。Noise2Noise方法的基本假设就是训练集具有0均值的噪声，因此在Noise2Noise的学习任务中采用L2 loss函数更合理。
3.3	参数优化策略
深度学习的根本任务是将网络参数优化，使得Loss最小。优化算法的选择直接影响了模型运算时间和运算量。

https://sirlis.gitee.io/deep-learning-basic-hp-and-opt/

由于神经网络结构复杂，对应的函数形式无法解析地求出极值，学界普遍采用以梯度下降为基础的数值优化手段。

梯度下降法的数学解释如下：
如果函数F(x)在点a处可微而且有定义，那么函数F(x)在a点沿着梯度相反的方向-delta(F(a))下降得最快。通过迭代过程，最终可以下降到导数为0的点。当此点是全局最小值时，模型参数便收敛到了最优解。
传统的优化器采用的是批量梯度下降策略（BGD），在每一轮训练中，需要对全部样本进行梯度计算，然后取平均值进行权值更新。当数据集增大时，这种策略带来了极大的运算量；同时，朴素的梯度下降有可能收敛到局部最小值（鞍点）。为了提高优化速度，并且避免收敛到局部极值，学界发展出了几种不同的优化器。

第四章 数值实验


在实验过程中，我们构造了具有不同信噪比的图片训练集，以对比三种去噪方法在不同信噪比下的表现。
信噪比的定义：
图片信噪比是衡量图片中噪声信号与有效信号占比的数值指标，其计算公式如下：


为了构造具有不同信噪比的数据集，我们编写了construct_image_with_SNR函数，用于将洁净的图片image，给定期望的SNR值，计算出对应的噪声强度施加在image上，从而得到噪声图片image。


保存模型

N2N方法的图像对比
10组不同信噪比的图像及其去噪后图片效果对比：

在10组信噪比中，SNR为0.064到0.5的9组图像中，可以识别出蛋白质结构实体的轮廓。
每组图片都由实体部分和底噪部分组成，底噪部分在洁净图片中是像素值严格等于0的点，加上噪声后成为底噪。可以看出，9组图片的实体部分跟底噪部分的对比度都有所增强，说明N2N降噪算法有效地降低了底噪强度，凸显了蛋白质结构实体部分。
在SNR值为0.01的降噪任务中，由于信噪比过低，带噪声图片和降噪后图片都无法清晰辨认实体部分的轮廓，但是可以发现降噪后图片有多处噪声被减弱（颜色越接近黑色代表像素值接近0）。
从蛋白质结构实体看，除开SNR值为0.228和0.01的两组图片，其他实验组均较好地保留了实体的结构细节；尤其SNR值为0.337时，降噪结果相比降噪前保留了更多的细节。在降噪的同时，可以发现每组图片都出现了不同程度上的模糊。其中第7和第9组图片的模糊程度较轻，而第1,2,3组的模糊程度较重，反映出N2N降噪的模糊程度随着SNR值提高而改善。

N2N方法的FRC
为了从FRC的角度衡量降噪效果，我们对每组图片中降噪后图片与洁净图片计算FRC曲线，以对比不同信噪比下图片的去噪效果。

FRC反映的是两张图片在空间频域上的相关性。由于各组实验的图片尺寸一致，因此空间频率域可归一化为范围0到1以方便讨论。一般来说，图片的噪声分量频率较高，降噪后图片仍带有部分噪声，因此预期的FRC曲线将呈现FRC值随空间频率增大而降低的趋势（反映了图片在低频部分一致，在高频噪声部分差异较大的特点）。
为了方便观察，将10组实验的FRC曲线图绘制在两张图片中。
首先观察图一可以发现，当SNR值为0.01时，FRC曲线急速下降，说明N2N算法在此SNR值下降噪效果较差，与肉眼观察结果一致。
第2到9组图片呈现SNR值越大，FRC值越高的趋势；说明在FRC指标下，N2N算法的表现随着SNR值提高而有所改善。其中有部分SNR值较低，但是FRC曲线值较高的图片组（SNR=0.337和SNR=0.119），考虑到图片噪声以及降噪训练过程中有一定随机性，可视为随机干扰的作用。

总结来说，各个实验组基本符合一般FRC曲线的延伸趋势，说明经过N2N是降噪后仍不能完全去除高频噪声分量；当SNR值较大，也即噪声强度较小时，N2N算法降噪结果与洁净图片更加接近。

N2N的CC

|   SNR   |   inp   |     out |
| ---- | ---- | ---- |
|0.01|0.067|0.099|
|0.064|0.399|0.857|
|0.119|0.624|0.877|
|0.173|0.761|0.879|
|0.228|0.839|0.84|
|0.282|0.886|0.876|
|0.337|0.916|0.892|
|0.391|0.936|0.86|
|0.446|0.949|0.87|
|0.5|0.959|0.881|

从互相关系数上看，在前5组图片中，降噪图片相比带噪声图片，与洁净图片的互相关系数更大；当SNR继续增大，带噪声图片与洁净图片的互相关系数更大。同时，随着SNR增大, 噪声图片与洁净图片互相关系数提高；降噪图片与洁净图片互相关系数降低。
对此现象的解释是：经过N2N降噪处理后，蛋白质实体部分经过降噪，像素值发生改变，会破坏部分细节，使得实体部分稍有偏离洁净图片；同时底噪部分也被大大降低，使得底噪部分更加接近洁净图片。当SNR值较小时，噪声大，图片的底噪占主要影响，因此经过降噪后图像与原图更加接近；当SNR值较大是，噪声小，图片的底噪占次要影响，即使N2N有效地降低了底噪，但仍不抵实体部分的影响，因此互相关系数降低。

总体来说，因为一张图片包括空白底噪和实体部分；而互相关系数计算的是单个数值，能从整体上反映两幅图片的差异，但也因此无法正确反映降噪算法对降低底噪的积极作用。

N2N的SSIM

N2V方法的直观效果：
从10组图片观察得知，在SNR=0.01下，噪声图片与去噪后图片都无法提取出实体部分的轮廓，而剩余9组图片的底噪都被降低，实体部分更加清晰，此结果与N2N方法相近。其不同之处在于，N2N方法对底噪去除更彻底，而N2V去除底噪后仍可以看到明显的灰色光晕。

N2V方法的FRC
从FRC的指标来看，N2V方法也大致呈现随着SNR值提高，FRC曲线有所改善的趋势。与N2N不同之处在于，N2V的实验结果中除了第一二组，其他8组曲线的形状较为接近。


N2V方法的CC
| SNR | Noised | Denoised |
|---- |----- | ----- |
|0.01|0.067|0.352|
|0.064|0.399|0.859|
|0.119|0.628|0.884|
|0.173|0.761|0.875|
|0.228|0.84|0.857|
|0.282|0.885|0.845|
|0.337|0.916|0.839|
|0.391|0.936|0.837|
|0.446|0.949|0.835|
|0.5|0.959|0.834|

与N2N方法相近，在前5组图片中，降噪图片相比带噪声图片，与洁净图片的互相关系数更大；当SNR继续增大，带噪声图片与洁净图片的互相关系数更大。随着SNR增大，降噪图片与洁净图片互相关系数有所降低。

滤波器方法的效果：
我们实验中采用低通滤波器，将高频分量去掉。实验结果表明，低通滤波器的降噪效果非常依赖于滤波阈值的选取。

滤波器的FRC

滤波器的CC

滤波器的SSIM
致  谢
××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××
××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××



 
       毕业论文（设计）成绩表

导师评语








建议成绩                   指导教师（签字）           
答辩委员会意见


答辩委员会负责人（签字）                 



成绩                     学院（盖章）                                      
    年   月    日

